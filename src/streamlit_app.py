# chatbot.py
import os
from pathlib import Path
import base64
import clipboard, pyperclip
import streamlit as st
from langchain import hub
from langchain_openai import AzureChatOpenAI
from langchain.schema import (HumanMessage, AIMessage)
# from langchain.chains import LLMChain
# from langchain import PromptTemplate, ChatPrompmtTemplate
from langchain import PromptTemplate
from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings
from langchain_community.document_loaders import UnstructuredMarkdownLoader, TextLoader
from langchain_core.runnables import RunnablePassthrough
from langchain_text_splitters import RecursiveCharacterTextSplitter
from dotenv import load_dotenv
from streamlit_option_menu import option_menu

from utils.connect_blobDB import connect_blobDB
from utils.split_pdf import process_pdf_from_blob
from utils.keywords_pdf_mapping import load_keyword_mapping, find_matching_files
from utils.custom_notifications import custom_notification
from ui_parts.streamlit_clipboard_with_chat import chat_message_with_copy

# .envãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
def load_template(file_path):
    """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€å„è¡Œã®å…ˆé ­ã®ç©ºç™½ã®ã¿ã‚’å‰Šé™¤ã—ã¾ã™ã€‚

    lstrip()ã‚’ä½¿ç”¨:
    - strip()ã¨é•ã„ã€è¡Œæœ«ã®ç©ºç™½ã‚„æ”¹è¡Œã‚’ä¿æŒ
    - ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®æ§‹é€ ï¼ˆã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã€ç©ºè¡Œï¼‰ã‚’ç¶­æŒã—ã¤ã¤ã€ä¸è¦ãªè¡Œé ­ã®ç©ºç™½ã‚’é™¤å»
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            return ''.join(line.lstrip() for line in file)
    except FileNotFoundError:
        st.error(f"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
        return None
    except Exception as e:
        st.error(f"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None


def on_copy_click(text):
    st.session_state.copied.append(text)
    pyperclip.copy(text)


def main():
    st.set_page_config(
        page_title="ãƒ¡ãƒ¼ãƒ«è¿”ä¿¡ãƒ»ç”»åƒèª­ã¿è¾¼ã¿AI",
        page_icon="ğŸ¤–"
    )
    reply_email=os.environ['PULL_OPTION_REPLY_EMAIL']
    reply_from_picture= os.environ['PULL_OPTION_REPLY_FROM_PICTURE']
    # reply_from_email_using_pdfinfo = os.environ['PULL_OPTION_REPLY_FROM_EMAIL_USING_PDF']
    reply_from_email_using_pdfinfo = os.environ['PULL_OPTION_REPLY_FROM_EMAIL_USING_PDFINFO']
    task = st.sidebar.selectbox(
    'AIã«å®Ÿæ–½ã•ã›ãŸã„ã‚¿ã‚¹ã‚¯ã‚’é¸ã‚“ã§ãã ã•ã„ï¼',
    (reply_from_email_using_pdfinfo, reply_email, reply_from_picture)
    )
    if task == reply_email:
    # ãƒ¡ãƒ¼ãƒ«è¿”ä¿¡AIã®å‡¦ç†
        # chain = initialize_chain() # RAGã‚’ä½¿ã†éš›ã«åˆ©ç”¨ã™ã‚‹
        llm = AzureChatOpenAI(
            azure_endpoint= os.environ['AZURE_OPEN_AI_END_POINT'],
            openai_api_version="2023-03-15-preview",
            # openai_api_version="2023-12-01-preview",
            deployment_name= os.environ['AZURE_OPENAI_DEPLOYMENT_NAME'],
            openai_api_key= os.environ['AZURE_OPEN_AI_API_KEY'],
            openai_api_type="azure",
        )

        # ãƒšãƒ¼ã‚¸ã®è¨­å®š
        st.header(reply_email+" ğŸ¤–")
        nortification_contents_nouse_webcontents = load_template(Path(__file__).parent.parent / "resources" / "text" / "nortification_contents_nouse_webcontents.txt")
        custom_notification('warning', nortification_contents_nouse_webcontents)

        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
        if "messages" not in st.session_state:
            st.session_state.messages = []

        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’è¨­å®š
        template_path = Path(__file__).parent.parent / "resources" / "email_template_content.txt"
        email_template_content = load_template(template_path)
        if email_template_content is None:
            return

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’æ ¼ç´
        template = f"""
    
        {email_template_content}
        
        ## å—ä¿¡ã—ãŸãƒ¡ãƒ¼ãƒ«
        {{received_mail}}
        """
        
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
        if user_input := st.chat_input("ãƒ¡ãƒ¼ãƒ«ã®å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"):
            st.session_state.messages.append(HumanMessage(content=user_input))
            with st.spinner("GPTãŒè¿”ä¿¡ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™..."):
                doctor_response_template = PromptTemplate(
                    input_variables=["received_mail"],
                    template=template,
                    )
                doctor_response_template.format(received_mail=user_input)
                # print(user_input, type(user_input))
                # print(doctor_response_template)
                # print(type(doctor_response_template.format(received_mail=user_input)))
                response = llm.invoke(doctor_response_template.format(received_mail=user_input))
            st.session_state.messages.append(AIMessage(content=response.content))
    
        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
        messages = st.session_state.get('messages', [])
        for message in messages:
            if isinstance(message, AIMessage):
                with st.chat_message('assistant'):
                    st.markdown(message.content)
            elif isinstance(message, HumanMessage):
                with st.chat_message('user'):
                    st.markdown(message.content)
            else:
                st.write(f"System message: {message.content}")

    elif task == reply_from_email_using_pdfinfo:
        keywords_pdf_mapping_csv_file = Path(__file__).parent.parent / "resources" / "csv" / "keywords_pdf_mapping.csv"
        keyword_mapping = load_keyword_mapping(keywords_pdf_mapping_csv_file)
        pdfs_keyword_mapping  = {value:key for key, value in keyword_mapping.items()}

        container_client = connect_blobDB(
            connection_string=os.environ['AZURE_BLOB_CONNECTION_STRING'],
            container_name=os.environ['AZURE_BLOB_CONTAINER_NAME']
        )
            
        # ãƒ¡ãƒ¼ãƒ«è¿”ä¿¡AIã®å‡¦ç†
        # chain = initialize_chain() # RAGã‚’ä½¿ã†éš›ã«åˆ©ç”¨ã™ã‚‹
        llm = AzureChatOpenAI(
            azure_endpoint= os.environ['AZURE_OPEN_AI_END_POINT_CHAT'],
            openai_api_version="2023-03-15-preview",
            # openai_api_version="2023-12-01-preview",
            deployment_name= os.environ['AZURE_OPENAI_DEPLOYMENT_NAME_CHAT'],
            openai_api_key= os.environ['AZURE_OPEN_AI_API_KEY_CHAT'],
            openai_api_type="azure",
        )
        # ãƒšãƒ¼ã‚¸ã®è¨­å®š
        st.header(reply_from_email_using_pdfinfo+" ğŸ¤–")
        nortification_contents_use_webcontents = load_template(Path(__file__).parent.parent / "resources" / "text" / "nortification_contents_use_webcontents.txt")
        custom_notification('success', nortification_contents_use_webcontents)

        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
        # äºº or AIã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        if "messages" not in st.session_state:
            st.session_state.messages = []
        
        # æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼‹PDFå
        if "search_document" not in st.session_state:
            st.session_state.search_document = []
        
        # ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã«æ ¼ç´ã™ã‚‹æ–‡è¨€
        if "copied" not in st.session_state: 
            st.session_state.copied = []

        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’è¨­å®š
        template_path = Path(__file__).parent.parent / "resources" / "email_template_content.txt"
        email_template_content = load_template(template_path)
        if email_template_content is None:
            return
                
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’æ ¼ç´
        template = f"""
        ## äº‹å‰æƒ…å ±
        {{pdf_info}}
        
        {email_template_content}

        ## å—ä¿¡ã—ãŸãƒ¡ãƒ¼ãƒ«
        {{received_mail}}
        """
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
        if user_input := st.chat_input("ãƒ¡ãƒ¼ãƒ«ã®å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"):
            st.session_state.messages.append(HumanMessage(content=user_input))
            
            if container_client:
                pdf_blob_name = find_matching_files(user_input, keyword_mapping)[0] #ä¸€ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«é™å®š
                documents = process_pdf_from_blob(container_client, pdf_blob_name)
                pdf_info = "".join(documents) if documents else "äº‹å‰æƒ…å ±ãªã—"

            with st.spinner("GPTãŒè¿”ä¿¡ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™..."):
                doctor_response_template = PromptTemplate(
                    input_variables=["received_mail", "pdf_info"],
                    template=template,
                    )
                doctor_response_template.format(received_mail=user_input, pdf_info=pdf_info)
                # print(user_input, type(user_input))
                # print(doctor_response_template)
                # print(type(doctor_response_template.format(received_mail=user_input)))
                response = llm.invoke(doctor_response_template.format(received_mail=user_input, pdf_info=pdf_info))
                # st.session_state.copied.append(response.content)

            st.session_state.messages.append(AIMessage(content=response.content))

            if pdf_blob_name == "":
                st.session_state.search_document.append(AIMessage(content="ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼šãªã—  \nå‚ç…§ãƒ•ã‚¡ã‚¤ãƒ«ï¼šãªã—"))
            else:
                st.session_state.search_document.append(AIMessage(content="ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼š{}  \nå‚ç…§ãƒ•ã‚¡ã‚¤ãƒ«ï¼š{}".format(str(pdfs_keyword_mapping[pdf_blob_name]), str(pdf_blob_name))))


        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
        messages = st.session_state.get('messages', [])
        search_documents = st.session_state.get('search_document', [])
        copied = st.session_state.get("copied", [])
        # for message in messages:
        for i in range(len(messages)):
            # if isinstance(message, AIMessage):
            if isinstance(messages[i], AIMessage):
                with st.chat_message('assistant'):
                    # st.markdown(message.content)
                    st.markdown(messages[i].content)
                    chat_message_with_copy(messages[i].content)
                # st.button("ğŸ“‹", on_click=on_copy_click, args=(messages[i].content,))
                # st.code(messages[i].conte)nt)
                with st.chat_message('assistant'):                        
                    st.markdown(search_documents[i//2].content)
            # elif isinstance(message, HumanMessage):
            elif isinstance(messages[i], HumanMessage):
                with st.chat_message('user'):
                    # st.markdown(message.content)
                    st.markdown(messages[i].content)
            else:
                # st.write(f"System message: {message.content}")
                st.write(f"System message: {messages[i].content}")
    
    elif task == reply_from_picture:
        st.header(reply_from_picture+" ğŸ¤–")
        image_template = """
        ä¸‹è¨˜ã®ç”»åƒã«ã¤ã„ã¦èª¬æ˜ã—ã¦ä¸‹ã•ã„
        
        {image_base64}
        """


        if uploaded_image := st.file_uploader('ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ä¸‹ã•ã„ã€‚(æ‹¡å¼µå­: png, jpg, jpeg)', type=['png', 'jpg', 'jpeg']):
            pass
            # uploaded_image_base64 = str(base64.b64encode(uploaded_image).decode('utf-8'))
            
        #     image_responce_template = ChatPrompmtTemplate.from_messages([
        #         SystemMessages(c)

        #     ])
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
        if user_input := st.chat_input("ã€â€»ç¾åœ¨ä½œæˆä¸­ã€‘ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»åƒã«é–¢é€£ã—ãŸãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã¯ç¾åœ¨ä½œæˆä¸­ã§ã™"):
            st.session_state.messages.append(HumanMessage(content=user_input))
            with st.spinner("GPTãŒè¿”ä¿¡ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™..."):
                doctor_response_template = PromptTemplate(
                    input_variables=["received_mail"],
                    template=template,
                    )
                doctor_response_template.format(received_mail=user_input)
                # print(user_input, type(user_input))
                # print(doctor_response_template)
                # print(type(doctor_response_template.format(received_mail=user_input)))
                response = llm.invoke(doctor_response_template.format(received_mail=user_input))
            st.session_state.messages.append(AIMessage(content=response.content))
    
        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
        messages = st.session_state.get('messages', [])
        for message in messages:
            if isinstance(message, AIMessage):
                with st.chat_message('assistant'):
                    st.markdown(message.content)
            elif isinstance(message, HumanMessage):
                with st.chat_message('user'):
                    st.markdown(message.content)
            else:
                st.write(f"System message: {message.content}")


if __name__ == '__main__':
    # print("hello")
    main()